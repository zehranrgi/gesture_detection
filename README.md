# gesture_detection




I worked with 4 classes in this project. These are: call, vletter, thumbs up, thumsdown.

I edited the codes on Ubuntu 21.04 version,Jupyter Notebook, Visual Code, NVDIA 460, CUDA 11.2 , CudNN 8. 

I also put the pipeline.config which was very challenging because even with one missing bracket, it could be broken. 

I encountered a lot of problems with the code(because his code was okay with Win OS), if you use the codes and if there is a problem, you can leave a comment.


Some output: 



![vletter](https://user-images.githubusercontent.com/70450368/125589426-70c1d2ba-3b70-47b8-8846-f9dfe8594acf.png)
![call](https://user-images.githubusercontent.com/70450368/125589407-8f2a94bc-5a69-4b3a-86d5-c02bd0e47f6e.png)
![thumsdown](https://user-images.githubusercontent.com/70450368/125589417-8bb738a1-294e-4687-9ef2-61336b402932.png)
![thumsup](https://user-images.githubusercontent.com/70450368/125589422-a1776717-a51a-4fd1-8a12-178d0d1ee7d0.png)
![tensorboard_train](https://user-images.githubusercontent.com/70450368/125589413-44a7586a-336d-4af2-84f5-1378bd9b7376.png)













completed the following:

A. Gesture Detection - this is the first project where you'll be able to build a model that detects different gestures

B. Face Sentiment Detection - here you'll learn how to estimate facial sentiment using Tensorflow Object Detection on a Raspberry Pi with TFLite 




