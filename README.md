# gesture_detection




I worked with 4 classes in this project. These are: call, vletter, thumbs up, thumsdown. I edited the codes on Ubuntu 21.04 version. I also put the pipeline.config which was very challenging because even with one missing bracket, it could be broken. I encountered a lot of problems with the code, if you use the codes and if there is a problem, you can leave a comment.


Some output: 



![call](https://user-images.githubusercontent.com/70450368/125589407-8f2a94bc-5a69-4b3a-86d5-c02bd0e47f6e.png)
![thumsdown](https://user-images.githubusercontent.com/70450368/125589417-8bb738a1-294e-4687-9ef2-61336b402932.png)
![thumsup](https://user-images.githubusercontent.com/70450368/125589422-a1776717-a51a-4fd1-8a12-178d0d1ee7d0.png)
![vletter](https://user-images.githubusercontent.com/70450368/125589426-70c1d2ba-3b70-47b8-8846-f9dfe8594acf.png)
![tensorboard_train](https://user-images.githubusercontent.com/70450368/125589413-44a7586a-336d-4af2-84f5-1378bd9b7376.png)












I compiled the codes with @nicknochnack. 

His video was about 5 hours, I completed the following:

A. Gesture Detection - this is the first project where you'll be able to build a model that detects different gestures

B. Microscope Based Defect Detection - here we'll leverage a USB microscope to detect defects in LEDs and PCBs using TFOD and Python

C. Web Direction Detection - in this model you'll learn how to detect hand directions for integration in a React Js Web App with Tensorflow Js

D. Face Sentiment Detection - here you'll learn how to estimate facial sentiment using Tensorflow Object Detection on a Raspberry Pi with TFLite 




