{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WORKSPACE_PATH': 'Tensorflow/workspace',\n",
       " 'SCRIPTS_PATH': 'Tensorflow/scripts',\n",
       " 'APIMODEL_PATH': 'Tensorflow/models',\n",
       " 'ANNOTATION_PATH': 'Tensorflow/workspace/annotations',\n",
       " 'IMAGE_PATH': 'Tensorflow/workspace/images',\n",
       " 'MODEL_PATH': 'Tensorflow/workspace/models',\n",
       " 'PRETRAINED_MODEL_PATH': 'Tensorflow/workspace/pre-trained-models',\n",
       " 'CHECKPOINT_PATH': 'Tensorflow/workspace/models/my_ssd_mobnet',\n",
       " 'OUTPUT_PATH': 'Tensorflow/workspace/models/my_ssd_mobnet/export',\n",
       " 'TFJS_PATH': 'Tensorflow/workspace/models/my_ssd_mobnet/tfjsexport',\n",
       " 'TFLITE_PATH': 'Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport',\n",
       " 'PROTOC_PATH': 'Tensorflow/protoc'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use conda: I generally don't use pip install from here. Because conda can be problematic with \n",
    "# installing pip and also conda command. [I just prefer jupyter notebook without conda.]\n",
    "if os.name=='nt' or \"posix\":\n",
    "#     !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to also install git. \n",
    "# For ubuntu sudo apt-install git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iA1DIq5OpfDE"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rJjMHbnDs3Tv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/zehranrgi/Documents/Projects/what_is_mygesture/Tensorflow/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: avro-python3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (1.9.2.1)\n",
      "Requirement already satisfied: apache-beam in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (2.31.0)\n",
      "Requirement already satisfied: pillow in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (8.3.1)\n",
      "Requirement already satisfied: lxml in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (4.6.3)\n",
      "Requirement already satisfied: matplotlib in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (3.4.2)\n",
      "Requirement already satisfied: Cython in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (0.29.23)\n",
      "Requirement already satisfied: contextlib2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (2.0.2)\n",
      "Requirement already satisfied: lvis in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (1.7.0)\n",
      "Requirement already satisfied: pandas in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: tf-models-official in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.19.3)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.34.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (3.17.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from apache-beam->object-detection==0.1) (2021.1)\n",
      "Requirement already satisfied: docopt in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from httplib2<0.20.0,>=0.8->apache-beam->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.26.6)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from lvis->object-detection==0.1) (0.10.0)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Using cached opencv_python-4.5.3.56-cp39-cp39-manylinux2014_x86_64.whl (49.9 MB)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from lvis->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: setuptools>=18.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from pycocotools->object-detection==0.1) (57.1.0)\n",
      "Requirement already satisfied: sacrebleu in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (1.5.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.5.3.56-cp39-cp39-manylinux2014_x86_64.whl (37.1 MB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (5.8.0)\n",
      "Requirement already satisfied: tensorflow-addons in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (0.13.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: gin-config in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: seqeval in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (2.20.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: sentencepiece in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tf-models-official->object-detection==0.1) (4.3.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.31.0)\n",
      "Requirement already satisfied: google-auth<2dev,>=1.16.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.32.1)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-auth<2dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.19.0)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.7.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (2.20)\n",
      "Requirement already satisfied: tqdm in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.61.2)\n",
      "Requirement already satisfied: python-slugify in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown>=2.6.8 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: portalocker==2.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from sacrebleu->tf-models-official->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from seqeval->tf-models-official->object-detection==0.1) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.12.1)\n",
      "Requirement already satisfied: promise in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1658948 sha256=2c9bee5524ea6adbf55ed058e3c5451ac2bf8a1c805aaa37a4cbcf94d5dca2dd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nfcc55ac/wheels/5f/71/82/e9526c84b6acec7906459334abc704f4e333f3a3b3a3cd891e\n",
      "Successfully built object-detection\n",
      "Installing collected packages: opencv-python-headless, opencv-python, object-detection\n",
      "  Attempting uninstall: object-detection\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "Successfully installed object-detection-0.1 opencv-python-4.5.3.56 opencv-python-headless-4.5.3.56\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "#     !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-14 10:31:38.013474: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Running tests under Python 3.9.5: /home/zehranrgi/Documents/Projects/Tensorflow/venv/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2021-07-14 10:31:40.878500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-14 10:31:40.923862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:40.924442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 850M computeCapability: 5.0\n",
      "coreClock: 0.8625GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2021-07-14 10:31:40.924488: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-14 10:31:40.937635: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-14 10:31:40.937751: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-14 10:31:40.948157: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-14 10:31:40.952151: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-14 10:31:40.964284: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-14 10:31:40.968411: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-14 10:31:40.968619: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-14 10:31:40.968784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:40.969562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:40.970567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-14 10:31:40.970832: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-14 10:31:40.971390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:40.971918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 850M computeCapability: 5.0\n",
      "coreClock: 0.8625GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2021-07-14 10:31:40.972052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:40.972650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:40.973149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-14 10:31:40.973901: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-14 10:31:42.133589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-14 10:31:42.133624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-14 10:31:42.133632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-14 10:31:42.133823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:42.134122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:42.134428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:31:42.134681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1141 MB memory) -> physical GPU (device: 0, name: GeForce GTX 850M, pci bus id: 0000:01:00.0, compute capability: 5.0)\n",
      "/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/builders/model_builder.py:1088: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0714 10:31:42.424722 139906399008576 model_builder.py:1088] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.77s\n",
      "I0714 10:31:42.633617 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.77s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.43s\n",
      "I0714 10:31:43.061115 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.43s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n",
      "I0714 10:31:43.358474 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.2s\n",
      "I0714 10:31:43.556960 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "W0714 10:31:43.558948 139906399008576 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.71s\n",
      "I0714 10:31:45.263153 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.71s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0714 10:31:45.264192 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0714 10:31:45.284158 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0714 10:31:45.297763 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0714 10:31:45.311721 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "I0714 10:31:45.399685 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0714 10:31:45.481117 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "I0714 10:31:45.569355 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.2s\n",
      "I0714 10:31:45.770289 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.2s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "I0714 10:31:45.851384 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0714 10:31:45.873247 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0714 10:31:46.019277 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0714 10:31:46.019415 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0714 10:31:46.019487 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I0714 10:31:46.021415 139906399008576 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0714 10:31:46.035946 139906399008576 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0714 10:31:46.036091 139906399008576 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0714 10:31:46.089717 139906399008576 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0714 10:31:46.089874 139906399008576 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0714 10:31:46.226837 139906399008576 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0714 10:31:46.226983 139906399008576 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0714 10:31:46.368615 139906399008576 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0714 10:31:46.368763 139906399008576 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0714 10:31:46.581570 139906399008576 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0714 10:31:46.581719 139906399008576 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0714 10:31:46.786497 139906399008576 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0714 10:31:46.786644 139906399008576 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0714 10:31:47.064490 139906399008576 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0714 10:31:47.064634 139906399008576 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0714 10:31:47.134787 139906399008576 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0714 10:31:47.163011 139906399008576 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0714 10:31:47.212148 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0714 10:31:47.212351 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I0714 10:31:47.212441 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 4\n",
      "I0714 10:31:47.215316 139906399008576 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0714 10:31:47.231662 139906399008576 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0714 10:31:47.231841 139906399008576 efficientnet_model.py:147] round_filter input=16 output=16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0714 10:31:47.347181 139906399008576 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0714 10:31:47.347320 139906399008576 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0714 10:31:47.550378 139906399008576 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0714 10:31:47.550521 139906399008576 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0714 10:31:47.756253 139906399008576 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0714 10:31:47.756398 139906399008576 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0714 10:31:48.032447 139906399008576 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0714 10:31:48.032586 139906399008576 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0714 10:31:48.407180 139906399008576 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0714 10:31:48.407326 139906399008576 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0714 10:31:48.768800 139906399008576 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0714 10:31:48.768941 139906399008576 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0714 10:31:48.908990 139906399008576 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0714 10:31:48.936763 139906399008576 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0714 10:31:48.991344 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0714 10:31:48.991486 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0714 10:31:48.991557 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 5\n",
      "I0714 10:31:48.993027 139906399008576 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0714 10:31:49.006558 139906399008576 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0714 10:31:49.006678 139906399008576 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0714 10:31:49.116394 139906399008576 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0714 10:31:49.116539 139906399008576 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0714 10:31:49.323189 139906399008576 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0714 10:31:49.323331 139906399008576 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0714 10:31:49.526782 139906399008576 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0714 10:31:49.526928 139906399008576 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0714 10:31:49.806510 139906399008576 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0714 10:31:49.806651 139906399008576 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0714 10:31:50.060776 139906399008576 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0714 10:31:50.060918 139906399008576 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0714 10:31:50.404962 139906399008576 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0714 10:31:50.405104 139906399008576 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0714 10:31:50.541606 139906399008576 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0714 10:31:50.568404 139906399008576 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0714 10:31:50.622444 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0714 10:31:50.622592 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I0714 10:31:50.622663 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 6\n",
      "I0714 10:31:50.624207 139906399008576 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0714 10:31:50.637664 139906399008576 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0714 10:31:50.637796 139906399008576 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0714 10:31:50.739437 139906399008576 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0714 10:31:50.739570 139906399008576 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0714 10:31:50.927978 139906399008576 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0714 10:31:50.928118 139906399008576 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0714 10:31:51.115182 139906399008576 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0714 10:31:51.115312 139906399008576 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0714 10:31:51.628659 139906399008576 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0714 10:31:51.628801 139906399008576 efficientnet_model.py:147] round_filter input=112 output=136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0714 10:31:51.967975 139906399008576 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0714 10:31:51.968112 139906399008576 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0714 10:31:52.350050 139906399008576 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0714 10:31:52.350201 139906399008576 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0714 10:31:52.477534 139906399008576 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0714 10:31:52.503175 139906399008576 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0714 10:31:52.558221 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0714 10:31:52.558366 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I0714 10:31:52.558418 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0714 10:31:52.559787 139906399008576 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0714 10:31:52.573700 139906399008576 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0714 10:31:52.573828 139906399008576 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0714 10:31:52.677379 139906399008576 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0714 10:31:52.677521 139906399008576 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0714 10:31:52.947702 139906399008576 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0714 10:31:52.947839 139906399008576 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0714 10:31:53.201089 139906399008576 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0714 10:31:53.201221 139906399008576 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0714 10:31:53.600265 139906399008576 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0714 10:31:53.600409 139906399008576 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0714 10:31:53.986361 139906399008576 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0714 10:31:53.986496 139906399008576 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0714 10:31:54.487613 139906399008576 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0714 10:31:54.487755 139906399008576 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0714 10:31:54.620349 139906399008576 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0714 10:31:54.644230 139906399008576 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0714 10:31:54.715985 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0714 10:31:54.716130 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I0714 10:31:54.716182 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I0714 10:31:54.717472 139906399008576 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0714 10:31:54.729218 139906399008576 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0714 10:31:54.729352 139906399008576 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0714 10:31:55.100273 139906399008576 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0714 10:31:55.100419 139906399008576 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0714 10:31:55.422374 139906399008576 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0714 10:31:55.422500 139906399008576 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0714 10:31:55.735714 139906399008576 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0714 10:31:55.735848 139906399008576 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0714 10:31:56.192184 139906399008576 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0714 10:31:56.192342 139906399008576 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0714 10:31:56.716922 139906399008576 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0714 10:31:56.717080 139906399008576 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0714 10:31:57.362070 139906399008576 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0714 10:31:57.362233 139906399008576 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0714 10:31:57.575431 139906399008576 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0714 10:31:57.600203 139906399008576 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0714 10:31:57.680150 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0714 10:31:57.680295 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0714 10:31:57.680366 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0714 10:31:57.681823 139906399008576 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0714 10:31:57.695909 139906399008576 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0714 10:31:57.696040 139906399008576 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0714 10:31:57.871490 139906399008576 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0714 10:31:57.871641 139906399008576 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0714 10:31:58.286050 139906399008576 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0714 10:31:58.286209 139906399008576 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0714 10:31:58.886806 139906399008576 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0714 10:31:58.886946 139906399008576 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0714 10:31:59.443642 139906399008576 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0714 10:31:59.443779 139906399008576 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0714 10:31:59.927525 139906399008576 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0714 10:31:59.927661 139906399008576 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0714 10:32:00.738837 139906399008576 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0714 10:32:00.739008 139906399008576 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0714 10:32:00.933529 139906399008576 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0714 10:32:00.959351 139906399008576 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0714 10:32:01.073204 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0714 10:32:01.073347 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0714 10:32:01.073419 139906399008576 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I0714 10:32:01.074757 139906399008576 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0714 10:32:01.087751 139906399008576 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0714 10:32:01.087876 139906399008576 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0714 10:32:01.302052 139906399008576 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0714 10:32:01.302186 139906399008576 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0714 10:32:01.786992 139906399008576 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0714 10:32:01.787124 139906399008576 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0714 10:32:02.387669 139906399008576 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0714 10:32:02.387796 139906399008576 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0714 10:32:03.029909 139906399008576 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0714 10:32:03.030048 139906399008576 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0714 10:32:03.601501 139906399008576 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0714 10:32:03.601632 139906399008576 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0714 10:32:04.336484 139906399008576 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0714 10:32:04.336616 139906399008576 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0714 10:32:04.563693 139906399008576 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0714 10:32:04.586437 139906399008576 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 18.81s\n",
      "I0714 10:32:04.682781 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 18.81s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0714 10:32:04.691567 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0714 10:32:04.693048 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0714 10:32:04.693475 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0714 10:32:04.694698 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\r\n",
      "I0714 10:32:04.695882 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\r\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\r\n",
      "I0714 10:32:04.696237 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\r\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\r\n",
      "I0714 10:32:04.697033 139906399008576 test_util.py:2102] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 24 tests in 23.833s\r\n",
      "\r\n",
      "OK (skipped=1)\r\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall protobuf matplotlib -y\n",
    "# !pip install protobuf matplotlib==3.2 #these version up to you. Please check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- -------------------\r\n",
      "absl-py                       0.12.0\r\n",
      "apache-beam                   2.31.0\r\n",
      "argon2-cffi                   20.1.0\r\n",
      "astunparse                    1.6.3\r\n",
      "async-generator               1.10\r\n",
      "attrs                         21.2.0\r\n",
      "avro-python3                  1.9.2.1\r\n",
      "backcall                      0.2.0\r\n",
      "beautifulsoup4                4.9.3\r\n",
      "bleach                        3.3.0\r\n",
      "cachetools                    4.2.2\r\n",
      "certifi                       2021.5.30\r\n",
      "cffi                          1.14.6\r\n",
      "chardet                       4.0.0\r\n",
      "click                         7.1.2\r\n",
      "contextlib2                   21.6.0\r\n",
      "crcmod                        1.7\r\n",
      "cycler                        0.10.0\r\n",
      "Cython                        0.29.23\r\n",
      "debugpy                       1.3.0\r\n",
      "decorator                     5.0.9\r\n",
      "defusedxml                    0.7.1\r\n",
      "dill                          0.3.1.1\r\n",
      "dm-tree                       0.1.6\r\n",
      "docopt                        0.6.2\r\n",
      "entrypoints                   0.3\r\n",
      "fastavro                      1.4.2\r\n",
      "flatbuffers                   1.12\r\n",
      "future                        0.18.2\r\n",
      "gast                          0.4.0\r\n",
      "gin-config                    0.4.0\r\n",
      "google                        3.0.0\r\n",
      "google-api-core               1.31.0\r\n",
      "google-api-python-client      2.12.0\r\n",
      "google-auth                   1.32.1\r\n",
      "google-auth-httplib2          0.1.0\r\n",
      "google-auth-oauthlib          0.4.4\r\n",
      "google-cloud-bigquery         2.20.0\r\n",
      "google-cloud-core             1.7.1\r\n",
      "google-crc32c                 1.1.2\r\n",
      "google-pasta                  0.2.0\r\n",
      "google-resumable-media        1.3.1\r\n",
      "googleapis-common-protos      1.53.0\r\n",
      "grpcio                        1.34.1\r\n",
      "h5py                          3.1.0\r\n",
      "hdfs                          2.6.0\r\n",
      "httplib2                      0.19.1\r\n",
      "idna                          2.10\r\n",
      "ipykernel                     6.0.1\r\n",
      "ipython                       7.25.0\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    7.6.3\r\n",
      "jedi                          0.18.0\r\n",
      "Jinja2                        3.0.1\r\n",
      "joblib                        1.0.1\r\n",
      "jsonschema                    3.2.0\r\n",
      "jupyter                       1.0.0\r\n",
      "jupyter-client                6.1.12\r\n",
      "jupyter-console               6.4.0\r\n",
      "jupyter-core                  4.7.1\r\n",
      "jupyterlab-pygments           0.1.2\r\n",
      "jupyterlab-widgets            1.0.0\r\n",
      "kaggle                        1.5.12\r\n",
      "keras-nightly                 2.5.0.dev2021032900\r\n",
      "Keras-Preprocessing           1.1.2\r\n",
      "kiwisolver                    1.3.1\r\n",
      "lvis                          0.5.3\r\n",
      "lxml                          4.6.3\r\n",
      "Markdown                      3.3.4\r\n",
      "MarkupSafe                    2.0.1\r\n",
      "matplotlib                    3.4.2\r\n",
      "matplotlib-inline             0.1.2\r\n",
      "mistune                       0.8.4\r\n",
      "nbclient                      0.5.3\r\n",
      "nbconvert                     6.1.0\r\n",
      "nbformat                      5.1.3\r\n",
      "nest-asyncio                  1.5.1\r\n",
      "notebook                      6.4.0\r\n",
      "numpy                         1.19.3\r\n",
      "oauth2client                  4.1.3\r\n",
      "oauthlib                      3.1.1\r\n",
      "object-detection              0.1\r\n",
      "opencv-python                 4.5.1.48\r\n",
      "opencv-python-headless        4.5.3.56\r\n",
      "opt-einsum                    3.3.0\r\n",
      "packaging                     21.0\r\n",
      "pandas                        1.3.0\r\n",
      "pandocfilters                 1.4.3\r\n",
      "parso                         0.8.2\r\n",
      "pexpect                       4.8.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "Pillow                        8.3.1\r\n",
      "pip                           21.1.3\r\n",
      "pkg-resources                 0.0.0\r\n",
      "portalocker                   2.0.0\r\n",
      "prometheus-client             0.11.0\r\n",
      "promise                       2.3\r\n",
      "prompt-toolkit                3.0.19\r\n",
      "proto-plus                    1.19.0\r\n",
      "protobuf                      3.17.3\r\n",
      "psutil                        5.8.0\r\n",
      "ptyprocess                    0.7.0\r\n",
      "py-cpuinfo                    8.0.0\r\n",
      "pyarrow                       4.0.1\r\n",
      "pyasn1                        0.4.8\r\n",
      "pyasn1-modules                0.2.8\r\n",
      "pycocotools                   2.0.2\r\n",
      "pycparser                     2.20\r\n",
      "pydot                         1.4.2\r\n",
      "Pygments                      2.9.0\r\n",
      "pymongo                       3.11.4\r\n",
      "pyparsing                     2.4.7\r\n",
      "PyQt5                         5.15.4\r\n",
      "pyqt5-plugins                 5.15.4.2.2\r\n",
      "PyQt5-Qt5                     5.15.2\r\n",
      "PyQt5-sip                     12.9.0\r\n",
      "pyqt5-tools                   5.15.4.3.2\r\n",
      "pyrsistent                    0.18.0\r\n",
      "python-dateutil               2.8.1\r\n",
      "python-dotenv                 0.18.0\r\n",
      "python-slugify                5.0.2\r\n",
      "pytz                          2021.1\r\n",
      "PyYAML                        5.4.1\r\n",
      "pyzmq                         22.1.0\r\n",
      "qt5-applications              5.15.2.2.2\r\n",
      "qt5-tools                     5.15.2.1.2\r\n",
      "qtconsole                     5.1.1\r\n",
      "QtPy                          1.9.0\r\n",
      "requests                      2.25.1\r\n",
      "requests-oauthlib             1.3.0\r\n",
      "rsa                           4.7.2\r\n",
      "sacrebleu                     1.5.1\r\n",
      "scikit-learn                  0.24.2\r\n",
      "scipy                         1.7.0\r\n",
      "Send2Trash                    1.7.1\r\n",
      "sentencepiece                 0.1.96\r\n",
      "seqeval                       1.2.2\r\n",
      "setuptools                    57.1.0\r\n",
      "six                           1.15.0\r\n",
      "soupsieve                     2.2.1\r\n",
      "tensorboard                   2.5.0\r\n",
      "tensorboard-data-server       0.6.1\r\n",
      "tensorboard-plugin-wit        1.8.0\r\n",
      "tensorflow                    2.5.0\r\n",
      "tensorflow-addons             0.13.0\r\n",
      "tensorflow-datasets           4.3.0\r\n",
      "tensorflow-estimator          2.5.0\r\n",
      "tensorflow-gpu                2.5.0\r\n",
      "tensorflow-hub                0.12.0\r\n",
      "tensorflow-metadata           1.1.0\r\n",
      "tensorflow-model-optimization 0.6.0\r\n",
      "termcolor                     1.1.0\r\n",
      "terminado                     0.10.1\r\n",
      "testpath                      0.5.0\r\n",
      "text-unidecode                1.3\r\n",
      "tf-models-official            2.5.0\r\n",
      "tf-slim                       1.1.0\r\n",
      "threadpoolctl                 2.2.0\r\n",
      "tornado                       6.1\r\n",
      "tqdm                          4.61.2\r\n",
      "traitlets                     5.0.5\r\n",
      "typeguard                     2.12.1\r\n",
      "typing-extensions             3.7.4.3\r\n",
      "uritemplate                   3.0.1\r\n",
      "urllib3                       1.26.6\r\n",
      "uuid                          1.30\r\n",
      "wcwidth                       0.2.5\r\n",
      "webencodings                  0.5.1\r\n",
      "Werkzeug                      2.0.1\r\n",
      "wget                          3.2\r\n",
      "wheel                         0.36.2\r\n",
      "widgetsnbextension            3.5.1\r\n",
      "wrapt                         1.12.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-13 21:04:12--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.169.176, 2a00:1450:4017:80a::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.169.176|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19,56M  12,1MB/s    in 1,6s    \n",
      "\n",
      "2021-07-13 21:04:14 (12,1 MB/s) - ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz saved [20515344/20515344]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/workspace/pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "print(paths['PRETRAINED_MODEL_PATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'Call', 'id':1}, {'name':'VLetter', 'id':2}, {'name':'ThumbsUp', 'id':3}, {'name':'ThumbsDown', 'id':4}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvf5WccwrFGq",
    "outputId": "49902aeb-0bd7-4298-e1a0-5b4a64eb2064"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# IF YOU USE COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWpb_BVUpfDD",
    "outputId": "56ce2a3f-3933-4ee6-8a9d-d5ec65f7d73c"
   },
   "outputs": [],
   "source": [
    "#It will be in the script folder.\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will convert our images to file format that it can use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will fix this problem with reinstalling pycocotools -y.\n",
    "\n",
    "\n",
    "\n",
    "ValueError: numpy.ndarray size changed, may indicate binary incompatibility. \n",
    "Expected 88 from C header, got 80 from PyObject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to Copy mobilenet to the workspace/models/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/workspace/pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "print(paths['PRETRAINED_MODEL_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "print(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pipeline config file: (is belong to our modelzoo) \n",
    "\n",
    "1. fine_tune_checkpoint_type: \"PATH_TO_BE_CONFIGURED\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-14 10:32:10.671090: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQA13-afpfDF",
    "outputId": "907496a4-a39d-4b13-8c2c-e5978ecb1f10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 4\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     pad_to_multiple: 1\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 20000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.center_net.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check the pipeline.config again, you can see the path now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zehranrgi/Documents/Projects/what_is_mygesture'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.image_data_format()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 14:40:20.905056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 14:40:22.749329: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-13 14:40:22.775641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:22.776174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 850M computeCapability: 5.0\n",
      "coreClock: 0.8625GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2021-07-13 14:40:22.776201: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 14:40:22.778677: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-13 14:40:22.778766: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-13 14:40:22.779611: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-13 14:40:22.779847: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-13 14:40:22.782274: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-13 14:40:22.782907: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-13 14:40:22.783044: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-13 14:40:22.783184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:22.783771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:22.784273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-13 14:40:22.784542: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-13 14:40:22.785039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:22.785538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 850M computeCapability: 5.0\n",
      "coreClock: 0.8625GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2021-07-13 14:40:22.785614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:22.786152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:22.786674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-13 14:40:22.786717: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 14:40:23.234485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-13 14:40:23.234520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-13 14:40:23.234527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-13 14:40:23.234710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:23.234997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:23.235258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 14:40:23.235485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1302 MB memory) -> physical GPU (device: 0, name: GeForce GTX 850M, pci bus id: 0000:01:00.0, compute capability: 5.0)\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "W0713 14:40:23.237453 139683892299584 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0713 14:40:23.257509 139683892299584 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I0713 14:40:23.260921 139683892299584 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0713 14:40:23.261029 139683892299584 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0713 14:40:23.286425 139683892299584 deprecation.py:330] From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0713 14:40:23.289253 139683892299584 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0713 14:40:23.289392 139683892299584 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0713 14:40:23.289454 139683892299584 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0713 14:40:23.289515 139683892299584 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0713 14:40:23.291575 139683892299584 deprecation.py:330] From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0713 14:40:23.309635 139683892299584 deprecation.py:330] From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0713 14:40:29.080581 139683892299584 deprecation.py:330] From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0713 14:40:32.450385 139683892299584 deprecation.py:330] From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0713 14:40:35.138998 139683892299584 deprecation.py:330] From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-07-13 14:40:37.134213: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-13 14:40:37.158338: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2494205000 Hz\n",
      "/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "INFO:tensorflow:Error reported to Coordinator: in user code:\n",
      "\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:169 _dummy_computation_fn  *\n",
      "        return _compute_losses_and_predictions_dicts(model, features, labels)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:122 _compute_losses_and_predictions_dicts  *\n",
      "        prediction_dict = model.predict(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:570 predict  *\n",
      "        feature_maps = self._feature_extractor(preprocessed_inputs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:251 call  *\n",
      "        return self._extract_features(inputs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py:230 _extract_features  *\n",
      "        fpn_features = self._fpn_features_generator(fpn_input_image_features)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/feature_map_generators.py:655 call  *\n",
      "        top_down += residual\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper\n",
      "        raise e\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper\n",
      "        return func(x, y, name=name)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1565 _add_dispatch\n",
      "        return gen_math_ops.add_v2(x, y, name=name)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:532 add_v2\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n",
      "        ret = Operation(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n",
      "        raise ValueError(str(e))\n",
      "\n",
      "    ValueError: Dimensions must be equal, but are 20 and 19 for '{{node ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/add}} = AddV2[T=DT_FLOAT](ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape, ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd)' with input shapes: [24,20,20,256], [24,19,19,256].\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 334, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 695, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:169 _dummy_computation_fn  *\n",
      "        return _compute_losses_and_predictions_dicts(model, features, labels)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:122 _compute_losses_and_predictions_dicts  *\n",
      "        prediction_dict = model.predict(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:570 predict  *\n",
      "        feature_maps = self._feature_extractor(preprocessed_inputs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:251 call  *\n",
      "        return self._extract_features(inputs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py:230 _extract_features  *\n",
      "        fpn_features = self._fpn_features_generator(fpn_input_image_features)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/feature_map_generators.py:655 call  *\n",
      "        top_down += residual\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper\n",
      "        raise e\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper\n",
      "        return func(x, y, name=name)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1565 _add_dispatch\n",
      "        return gen_math_ops.add_v2(x, y, name=name)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:532 add_v2\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n",
      "        ret = Operation(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n",
      "        raise ValueError(str(e))\n",
      "\n",
      "    ValueError: Dimensions must be equal, but are 20 and 19 for '{{node ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/add}} = AddV2[T=DT_FLOAT](ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape, ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd)' with input shapes: [24,20,20,256], [24,19,19,256].\n",
      "\n",
      "I0713 14:40:43.041286 139676866295360 coordinator.py:217] Error reported to Coordinator: in user code:\n",
      "\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:169 _dummy_computation_fn  *\n",
      "        return _compute_losses_and_predictions_dicts(model, features, labels)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:122 _compute_losses_and_predictions_dicts  *\n",
      "        prediction_dict = model.predict(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:570 predict  *\n",
      "        feature_maps = self._feature_extractor(preprocessed_inputs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:251 call  *\n",
      "        return self._extract_features(inputs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py:230 _extract_features  *\n",
      "        fpn_features = self._fpn_features_generator(fpn_input_image_features)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/feature_map_generators.py:655 call  *\n",
      "        top_down += residual\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper\n",
      "        raise e\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper\n",
      "        return func(x, y, name=name)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1565 _add_dispatch\n",
      "        return gen_math_ops.add_v2(x, y, name=name)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:532 add_v2\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n",
      "        ret = Operation(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n",
      "        raise ValueError(str(e))\n",
      "\n",
      "    ValueError: Dimensions must be equal, but are 20 and 19 for '{{node ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/add}} = AddV2[T=DT_FLOAT](ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape, ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd)' with input shapes: [24,20,20,256], [24,19,19,256].\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 334, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 695, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:169 _dummy_computation_fn  *\n",
      "        return _compute_losses_and_predictions_dicts(model, features, labels)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:122 _compute_losses_and_predictions_dicts  *\n",
      "        prediction_dict = model.predict(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:570 predict  *\n",
      "        feature_maps = self._feature_extractor(preprocessed_inputs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:251 call  *\n",
      "        return self._extract_features(inputs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py:230 _extract_features  *\n",
      "        fpn_features = self._fpn_features_generator(fpn_input_image_features)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/feature_map_generators.py:655 call  *\n",
      "        top_down += residual\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper\n",
      "        raise e\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper\n",
      "        return func(x, y, name=name)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1565 _add_dispatch\n",
      "        return gen_math_ops.add_v2(x, y, name=name)\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:532 add_v2\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n",
      "        ret = Operation(\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n",
      "        raise ValueError(str(e))\n",
      "\n",
      "    ValueError: Dimensions must be equal, but are 20 and 19 for '{{node ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/add}} = AddV2[T=DT_FLOAT](ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape, ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd)' with input shapes: [24,20,20,256], [24,19,19,256].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/what_is_mygesture/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\r\n",
      "    tf.compat.v1.app.run()\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/absl/app.py\", line 303, in run\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/absl/app.py\", line 251, in _run_main\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/what_is_mygesture/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 106, in main\r\n",
      "    model_lib_v2.train_loop(\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py\", line 572, in train_loop\r\n",
      "    _ensure_model_is_built(detection_model, train_input,\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py\", line 173, in _ensure_model_is_built\r\n",
      "    strategy.run(\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1285, in run\r\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2833, in call_for_each_replica\r\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 678, in _call_for_each_replica\r\n",
      "    return mirrored_run.call_for_each_replica(\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 86, in call_for_each_replica\r\n",
      "    return wrapped(args, kwargs)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n",
      "    result = self._call(*args, **kwds)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\r\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 763, in _initialize\r\n",
      "    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\r\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\r\n",
      "    graph_function = self._create_graph_function(args, kwargs)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\r\n",
      "    func_graph_module.func_graph_from_py_func(\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\r\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\r\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n",
      "  File \"/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\r\n",
      "    raise e.ag_error_metadata.to_exception(e)\r\n",
      "ValueError: in user code:\r\n",
      "\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:104 call_for_each_replica  *\r\n",
      "        return _call_for_each_replica(strategy, fn, args, kwargs)\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:169 _dummy_computation_fn  *\r\n",
      "        return _compute_losses_and_predictions_dicts(model, features, labels)\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/model_lib_v2.py:122 _compute_losses_and_predictions_dicts  *\r\n",
      "        prediction_dict = model.predict(\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:570 predict  *\r\n",
      "        feature_maps = self._feature_extractor(preprocessed_inputs)\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:251 call  *\r\n",
      "        return self._extract_features(inputs)\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py:230 _extract_features  *\r\n",
      "        fpn_features = self._fpn_features_generator(fpn_input_image_features)\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/object_detection/models/feature_map_generators.py:655 call  *\r\n",
      "        top_down += residual\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper\r\n",
      "        raise e\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper\r\n",
      "        return func(x, y, name=name)\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\r\n",
      "        return target(*args, **kwargs)\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1565 _add_dispatch\r\n",
      "        return gen_math_ops.add_v2(x, y, name=name)\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:532 add_v2\r\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\r\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\r\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\r\n",
      "        ret = Operation(\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\r\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\r\n",
      "    /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\r\n",
      "        raise ValueError(str(e))\r\n",
      "\r\n",
      "    ValueError: Dimensions must be equal, but are 20 and 19 for '{{node ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/add}} = AddV2[T=DT_FLOAT](ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape, ssd_mobile_net_v2fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd)' with input shapes: [24,20,20,256], [24,19,19,256].\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I0713 16:07:30.480170 140195664578368 model_lib_v2.py:698] Step 2000 per-step time 0.362s\n",
    "INFO:tensorflow:{'Loss/classification_loss': 0.07822016,\n",
    " 'Loss/localization_loss': 0.01175597,\n",
    " 'Loss/regularization_loss': 0.14398871,\n",
    " 'Loss/total_loss': 0.23396485,\n",
    " 'learning_rate': 0.07991781}\n",
    "I0713 16:07:30.480467 140195664578368 model_lib_v2.py:701] {'Loss/classification_loss': 0.07822016,\n",
    " 'Loss/localization_loss': 0.01175597,\n",
    " 'Loss/regularization_loss': 0.14398871,\n",
    " 'Loss/total_loss': 0.23396485,\n",
    " 'learning_rate': 0.07991781}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqTV2jGBpfDH"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "1. Go here: \n",
    "\n",
    "~/Documents/Projects/what_is_mygesture/Tensorflow/workspace/models/my_ssd_mobnet/train\n",
    "\n",
    "2. To the terminal: \n",
    "\n",
    "$ tensorboard --logdir=.\n",
    "\n",
    "We can use tensorboard here. It will give a link like that: TensorBoard 2.5.0 at **http://localhost:6006/**\n",
    "\n",
    "1.2 Also from here:\n",
    "    \n",
    "~/Documents/Projects/what_is_mygesture/Tensorflow/workspace/models/my_ssd_mobnet/eval\n",
    "\n",
    "$ tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-14 10:33:07.447539: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-14 10:33:07.510341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.510690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 850M computeCapability: 5.0\n",
      "coreClock: 0.8625GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2021-07-14 10:33:07.510731: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-14 10:33:07.513428: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-14 10:33:07.513482: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-14 10:33:07.514355: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-14 10:33:07.514542: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-14 10:33:07.516926: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-14 10:33:07.517510: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-14 10:33:07.517617: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-14 10:33:07.517717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.517994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.518207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-14 10:33:07.519140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-14 10:33:07.519636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.519887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 850M computeCapability: 5.0\n",
      "coreClock: 0.8625GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2021-07-14 10:33:07.519958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.520230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.520450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-14 10:33:07.520486: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-14 10:33:07.960783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-14 10:33:07.960810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-14 10:33:07.960817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-14 10:33:07.960987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.961255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.961483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-14 10:33:07.961681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1138 MB memory) -> physical GPU (device: 0, name: GeForce GTX 850M, pci bus id: 0000:01:00.0, compute capability: 5.0)\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# 9. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Y_MKiuZ4pfDI"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Lx3crOhOzITB"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'call.bfdbcf68-dfdc-11eb-a0b1-d92864aec8ec.jpg')\n",
    "\n",
    "# You should write your img path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow/workspace/images/test/call.bfdbcf68-dfdc-11eb-a0b1-d92864aec8ec.jpg'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsNAaYAo0WVL"
   },
   "source": [
    "# 10. Real Time Detections from your Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python-headless 4.5.3.56\r\n",
      "Uninstalling opencv-python-headless-4.5.3.56:\r\n",
      "  Successfully uninstalled opencv-python-headless-4.5.3.56\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python-headless -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_grs6OGpfDJ"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection', image_np_with_detections)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        \n",
    "        cap.release()\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzlM4jt0pfDJ"
   },
   "source": [
    "# 10. Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "n4olHB2npfDJ"
   },
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "0AjO93QDpfDJ"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Lsp3tCpfDJ",
    "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --trained_checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet --output_directory=Tensorflow/workspace/models/my_ssd_mobnet/export\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sw1ULgHpfDJ",
    "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 23:42:44.121166: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 23:42:45.824742: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-13 23:42:45.846288: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2021-07-13 23:42:45.846325: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: zehranrgi-GE70-2PC\n",
      "2021-07-13 23:42:45.846338: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: zehranrgi-GE70-2PC\n",
      "2021-07-13 23:42:45.846422: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "2021-07-13 23:42:45.846449: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.84.0\n",
      "2021-07-13 23:42:45.846457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.84.0\n",
      "2021-07-13 23:42:45.846712: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0713 23:42:46.050693 139758161971008 deprecation.py:596] From /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f1b54622d30>, because it is not built.\n",
      "W0713 23:42:59.773182 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f1b54622d30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f1b5464e4f0>, because it is not built.\n",
      "W0713 23:42:59.888024 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f1b5464e4f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c500220>, because it is not built.\n",
      "W0713 23:42:59.888190 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c500220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c55c430>, because it is not built.\n",
      "W0713 23:42:59.888267 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c55c430>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f1b4c55c6d0>, because it is not built.\n",
      "W0713 23:42:59.888333 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f1b4c55c6d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c55cee0>, because it is not built.\n",
      "W0713 23:42:59.888395 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c55cee0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c55c490>, because it is not built.\n",
      "W0713 23:42:59.888454 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c55c490>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f1b4c508280>, because it is not built.\n",
      "W0713 23:42:59.888511 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f1b4c508280>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c508d60>, because it is not built.\n",
      "W0713 23:42:59.888569 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c508d60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c508640>, because it is not built.\n",
      "W0713 23:42:59.888625 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c508640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f1b4c508eb0>, because it is not built.\n",
      "W0713 23:42:59.888682 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f1b4c508eb0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b542fee80>, because it is not built.\n",
      "W0713 23:42:59.888739 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b542fee80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c436340>, because it is not built.\n",
      "W0713 23:42:59.888795 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c436340>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b5464ed60>, because it is not built.\n",
      "W0713 23:42:59.888850 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b5464ed60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c4464c0>, because it is not built.\n",
      "W0713 23:42:59.888907 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c4464c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c506340>, because it is not built.\n",
      "W0713 23:42:59.888962 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c506340>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c506b20>, because it is not built.\n",
      "W0713 23:42:59.889018 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c506b20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b543008b0>, because it is not built.\n",
      "W0713 23:42:59.889075 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b543008b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b54300ac0>, because it is not built.\n",
      "W0713 23:42:59.889136 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b54300ac0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c469040>, because it is not built.\n",
      "W0713 23:42:59.889193 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c469040>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c469760>, because it is not built.\n",
      "W0713 23:42:59.889248 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c469760>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b5464ed90>, because it is not built.\n",
      "W0713 23:42:59.889304 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b5464ed90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c461280>, because it is not built.\n",
      "W0713 23:42:59.889368 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c461280>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c4516d0>, because it is not built.\n",
      "W0713 23:42:59.889423 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c4516d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c451970>, because it is not built.\n",
      "W0713 23:42:59.889488 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c451970>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c451ca0>, because it is not built.\n",
      "W0713 23:42:59.889553 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c451ca0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c451cd0>, because it is not built.\n",
      "W0713 23:42:59.889607 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c451cd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c451820>, because it is not built.\n",
      "W0713 23:42:59.889671 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c451820>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c451700>, because it is not built.\n",
      "W0713 23:42:59.889735 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c451700>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b5464edc0>, because it is not built.\n",
      "W0713 23:42:59.889788 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b5464edc0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c5c70d0>, because it is not built.\n",
      "W0713 23:42:59.889852 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c5c70d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c45b0d0>, because it is not built.\n",
      "W0713 23:42:59.889919 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c45b0d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c45b100>, because it is not built.\n",
      "W0713 23:42:59.889975 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c45b100>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c45b610>, because it is not built.\n",
      "W0713 23:42:59.890029 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c45b610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c45b5b0>, because it is not built.\n",
      "W0713 23:42:59.890104 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c45b5b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c45b820>, because it is not built.\n",
      "W0713 23:42:59.890158 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c45b820>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b544596d0>, because it is not built.\n",
      "W0713 23:42:59.890214 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b544596d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c43b370>, because it is not built.\n",
      "W0713 23:42:59.890280 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c43b370>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b542aba60>, because it is not built.\n",
      "W0713 23:42:59.890357 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b542aba60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b54500100>, because it is not built.\n",
      "W0713 23:42:59.890436 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b54500100>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c6d7670>, because it is not built.\n",
      "W0713 23:42:59.890521 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c6d7670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b54336250>, because it is not built.\n",
      "W0713 23:42:59.890585 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b54336250>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b54336430>, because it is not built.\n",
      "W0713 23:42:59.890641 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b54336430>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c63ad30>, because it is not built.\n",
      "W0713 23:42:59.890696 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f1b4c63ad30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c63a310>, because it is not built.\n",
      "W0713 23:42:59.890751 139758161971008 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f1b4c63a310>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 23:43:07.871278: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0713 23:43:21.546213 139758161971008 save.py:238] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
      "/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "W0713 23:43:25.521522 139758161971008 save.py:1239] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/export/saved_model/assets\n",
      "I0713 23:43:25.830558 139758161971008 builder_impl.py:774] Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/export/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to Tensorflow/workspace/models/my_ssd_mobnet/export/pipeline.config\n",
      "I0713 23:43:26.624881 139758161971008 config_util.py:253] Writing pipeline config file to Tensorflow/workspace/models/my_ssd_mobnet/export/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTPmdqaXpfDK"
   },
   "source": [
    "# 11. Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ6UzY_fpfDK",
    "outputId": "0c84722e-1c2b-4002-d857-80827ade828a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Downloading tensorflowjs-3.7.0-py3-none-any.whl (64 kB)\n",
      "\u001b[K     || 64 kB 917 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflowjs) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflowjs) (2.5.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.3)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.34.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (57.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.32.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
      "Installing collected packages: tensorflowjs\n",
      "Successfully installed tensorflowjs-3.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "0oxbVynHpfDK"
   },
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2AGNmJpfDK",
    "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default Tensorflow/workspace/models/my_ssd_mobnet/export/saved_model Tensorflow/workspace/models/my_ssd_mobnet/tfjsexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7rfT4-hpfDK",
    "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 23:45:19.702206: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 23:45:21.964527: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-13 23:45:21.986026: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2021-07-13 23:45:21.986078: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: zehranrgi-GE70-2PC\n",
      "2021-07-13 23:45:21.986093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: zehranrgi-GE70-2PC\n",
      "2021-07-13 23:45:21.986179: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "2021-07-13 23:45:21.986218: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.84.0\n",
      "2021-07-13 23:45:21.986232: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.84.0\n",
      "2021-07-13 23:45:21.986452: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-13 23:45:30.791458: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2021-07-13 23:45:30.791588: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-07-13 23:45:30.811221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2494205000 Hz\n",
      "2021-07-13 23:45:31.062682: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 3841 nodes (3432), 8222 edges (7806), time = 150.948ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 3.372ms.\n",
      "\n",
      "2021-07-13 23:45:34.843281: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  debug_stripper: Graph size after: 3554 nodes (0), 7993 edges (0), time = 4.762ms.\n",
      "  model_pruner: Graph size after: 3111 nodes (-443), 7550 edges (-443), time = 39.806ms.\n",
      "  constant_folding: Graph size after: 1530 nodes (-1581), 5720 edges (-1830), time = 206.644ms.\n",
      "  arithmetic_optimizer: Graph size after: 1546 nodes (16), 5744 edges (24), time = 36.189ms.\n",
      "  dependency_optimizer: Graph size after: 1456 nodes (-90), 1648 edges (-4096), time = 29.02ms.\n",
      "  model_pruner: Graph size after: 1456 nodes (0), 1648 edges (0), time = 12.925ms.\n",
      "  constant_folding: Graph size after: 1456 nodes (0), 1648 edges (0), time = 43.167ms.\n",
      "  arithmetic_optimizer: Graph size after: 1456 nodes (0), 1648 edges (0), time = 31.481ms.\n",
      "  dependency_optimizer: Graph size after: 1456 nodes (0), 1648 edges (0), time = 18.625ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 2.639ms.\n",
      "  model_pruner: Graph size after: 1456 nodes (0), 1648 edges (0), time = 10.907ms.\n",
      "  constant_folding: Graph size after: 1456 nodes (0), 1648 edges (0), time = 42.491ms.\n",
      "  arithmetic_optimizer: Graph size after: 1456 nodes (0), 1648 edges (0), time = 34.3ms.\n",
      "  dependency_optimizer: Graph size after: 1456 nodes (0), 1648 edges (0), time = 18.689ms.\n",
      "  model_pruner: Graph size after: 1456 nodes (0), 1648 edges (0), time = 14.039ms.\n",
      "  constant_folding: Graph size after: 1456 nodes (0), 1648 edges (0), time = 40.901ms.\n",
      "  arithmetic_optimizer: Graph size after: 1456 nodes (0), 1648 edges (0), time = 33.965ms.\n",
      "  dependency_optimizer: Graph size after: 1456 nodes (0), 1648 edges (0), time = 20.121ms.\n",
      "\n",
      "2021-07-13 23:45:42.258215: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  remapper: Graph size after: 1420 nodes (-112), 1308 edges (-112), time = 4.742ms.\n",
      "  constant_folding: Graph size after: 1116 nodes (-304), 1308 edges (0), time = 46.836ms.\n",
      "  arithmetic_optimizer: Graph size after: 1116 nodes (0), 1308 edges (0), time = 19.483ms.\n",
      "  dependency_optimizer: Graph size after: 1116 nodes (0), 1308 edges (0), time = 10.984ms.\n",
      "  remapper: Graph size after: 1116 nodes (0), 1308 edges (0), time = 7.089ms.\n",
      "  constant_folding: Graph size after: 1116 nodes (0), 1308 edges (0), time = 27.716ms.\n",
      "  arithmetic_optimizer: Graph size after: 1116 nodes (0), 1308 edges (0), time = 20.831ms.\n",
      "  dependency_optimizer: Graph size after: 1116 nodes (0), 1308 edges (0), time = 12.053ms.\n",
      "\n",
      "Writing weight file Tensorflow/workspace/models/my_ssd_mobnet/tfjsexport/model.json...\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8_hm-itpfDK"
   },
   "outputs": [],
   "source": [
    "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 12. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/export_tflite_graph_tf2.py  --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --trained_checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet --output_directory=Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 23:46:31.043285: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 23:46:32.726741: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-13 23:46:32.746151: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2021-07-13 23:46:32.746186: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: zehranrgi-GE70-2PC\n",
      "2021-07-13 23:46:32.746196: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: zehranrgi-GE70-2PC\n",
      "2021-07-13 23:46:32.746260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "2021-07-13 23:46:32.746285: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.84.0\n",
      "2021-07-13 23:46:32.746293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.84.0\n",
      "2021-07-13 23:46:32.746523: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-13 23:46:38.531246: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2494205000 Hz\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f51881c2ee0>, because it is not built.\n",
      "W0713 23:46:40.604428 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f51881c2ee0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f51881704f0>, because it is not built.\n",
      "W0713 23:46:40.824779 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f51881704f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51681540d0>, because it is not built.\n",
      "W0713 23:46:40.824946 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51681540d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f5168154a60>, because it is not built.\n",
      "W0713 23:46:40.825017 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f5168154a60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f5168154970>, because it is not built.\n",
      "W0713 23:46:40.825078 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f5168154970>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51683f8e20>, because it is not built.\n",
      "W0713 23:46:40.825136 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51683f8e20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51683f84f0>, because it is not built.\n",
      "W0713 23:46:40.825192 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51683f84f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f51683a3310>, because it is not built.\n",
      "W0713 23:46:40.825248 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f51683a3310>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51683a35b0>, because it is not built.\n",
      "W0713 23:46:40.825303 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51683a35b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f5168147af0>, because it is not built.\n",
      "W0713 23:46:40.825362 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f5168147af0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f5168147250>, because it is not built.\n",
      "W0713 23:46:40.825417 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7f5168147250>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f5168147a00>, because it is not built.\n",
      "W0713 23:46:40.825471 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f5168147a00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f5168147b80>, because it is not built.\n",
      "W0713 23:46:40.825525 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f5168147b80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f5188170ac0>, because it is not built.\n",
      "W0713 23:46:40.825579 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f5188170ac0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51681236d0>, because it is not built.\n",
      "W0713 23:46:40.825632 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51681236d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680d6640>, because it is not built.\n",
      "W0713 23:46:40.825685 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680d6640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680d67c0>, because it is not built.\n",
      "W0713 23:46:40.825739 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680d67c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680d6d30>, because it is not built.\n",
      "W0713 23:46:40.825792 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680d6d30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680d6b20>, because it is not built.\n",
      "W0713 23:46:40.825846 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680d6b20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f516811dca0>, because it is not built.\n",
      "W0713 23:46:40.825901 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f516811dca0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f516811ddf0>, because it is not built.\n",
      "W0713 23:46:40.825958 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f516811ddf0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f5188170af0>, because it is not built.\n",
      "W0713 23:46:40.826012 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f5188170af0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51800836d0>, because it is not built.\n",
      "W0713 23:46:40.826066 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51800836d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51683dfb80>, because it is not built.\n",
      "W0713 23:46:40.826120 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51683dfb80>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51683df760>, because it is not built.\n",
      "W0713 23:46:40.826174 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51683df760>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51682f32e0>, because it is not built.\n",
      "W0713 23:46:40.826227 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51682f32e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51682f3c10>, because it is not built.\n",
      "W0713 23:46:40.826281 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51682f3c10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51681ae940>, because it is not built.\n",
      "W0713 23:46:40.826334 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51681ae940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51681aed60>, because it is not built.\n",
      "W0713 23:46:40.826388 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51681aed60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f5188170b20>, because it is not built.\n",
      "W0713 23:46:40.826441 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f5188170b20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680a4bb0>, because it is not built.\n",
      "W0713 23:46:40.826494 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680a4bb0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680b1e20>, because it is not built.\n",
      "W0713 23:46:40.826547 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680b1e20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680b1fa0>, because it is not built.\n",
      "W0713 23:46:40.826601 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680b1fa0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680b1970>, because it is not built.\n",
      "W0713 23:46:40.826654 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680b1970>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680b19d0>, because it is not built.\n",
      "W0713 23:46:40.826708 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680b19d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680ae040>, because it is not built.\n",
      "W0713 23:46:40.826760 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680ae040>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680ae5e0>, because it is not built.\n",
      "W0713 23:46:40.826817 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680ae5e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680b7940>, because it is not built.\n",
      "W0713 23:46:40.826871 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680b7940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680b7610>, because it is not built.\n",
      "W0713 23:46:40.826928 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680b7610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680a8160>, because it is not built.\n",
      "W0713 23:46:40.826982 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680a8160>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680a8430>, because it is not built.\n",
      "W0713 23:46:40.827037 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680a8430>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680a8bb0>, because it is not built.\n",
      "W0713 23:46:40.827091 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680a8bb0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680a8f10>, because it is not built.\n",
      "W0713 23:46:40.827165 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680a8f10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680ac220>, because it is not built.\n",
      "W0713 23:46:40.827224 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f51680ac220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680ac3d0>, because it is not built.\n",
      "W0713 23:46:40.827287 139990925268800 save_impl.py:76] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7f51680ac3d0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 23:46:48.734580: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0713 23:47:02.679559 139990925268800 save.py:238] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
      "/home/zehranrgi/Documents/Projects/Tensorflow/venv/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "W0713 23:47:06.744519 139990925268800 save.py:1239] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model/assets\n",
      "I0713 23:47:07.082182 139990925268800 builder_impl.py:774] Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflite_convert --saved_model_dir=Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model --output_file=Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 23:48:06.458411: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 23:48:08.029733: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-13 23:48:08.049965: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2021-07-13 23:48:08.050009: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: zehranrgi-GE70-2PC\n",
      "2021-07-13 23:48:08.050020: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: zehranrgi-GE70-2PC\n",
      "2021-07-13 23:48:08.050075: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "2021-07-13 23:48:08.050103: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.84.0\n",
      "2021-07-13 23:48:08.050113: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.84.0\n",
      "2021-07-13 23:48:08.050332: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-13 23:48:16.789553: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2021-07-13 23:48:16.789598: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2021-07-13 23:48:16.789614: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored change_concat_input_ranges.\n",
      "2021-07-13 23:48:16.791596: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model\n",
      "2021-07-13 23:48:16.875278: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2021-07-13 23:48:16.875327: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model\n",
      "2021-07-13 23:48:17.192343: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2021-07-13 23:48:17.255275: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2494205000 Hz\n",
      "2021-07-13 23:48:17.879973: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model\n",
      "2021-07-13 23:48:18.148792: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 1357204 microseconds.\n",
      "2021-07-13 23:48:19.193698: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What we can do for boosting the model?\n",
    "We can..\n",
    "\n",
    "1.  add more images.\n",
    "2.  increase num_steps= >2000\n",
    "3.  change architecture (modelzoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NQqZRdA21Uc"
   },
   "source": [
    "# 13. Zip and Export Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTVTGCQp2ZJJ"
   },
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whShhB0x3PYJ",
    "outputId": "b773201d-35c9-46a8-b893-4a76bd4d5d97"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfs-venv",
   "language": "python",
   "name": "tfs-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
